{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support vector machines (SVMs) are supervised algorithms for both classification and regression.\n",
    "Based on discriminative classification: rather than modeling each class, we simply find a line or curve (in two dimensions) or manifold (in multiple dimensions) that divides the classes from each other.\n",
    "\n",
    "Datapoints from different classes are separated by lines (if SVM uses a linear kernel) which have margins.\n",
    "These margins are maximized till they \"touch\" some datapoints.\n",
    "These datapoints are called \"support vectors\" and are the only datapoints that are considered for future predictions. Datapoints which are not in the margins don't influence the prediction.\n",
    "\n",
    "C parameter determines how tolerant is the margin with respect to data points inside itself. The lesser the more tolerant it is.\n",
    "\n",
    "**References**\n",
    "* [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html)\n",
    "* [An Idiot's guide to Support vector machines (SVMs)](http://web.mit.edu/6.034/wwwbob/svm-notes-long-08.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Environment settings\n",
    "data_path = 'Data/'\n",
    "\n",
    "# Deserialize previously saved data from \"preprocessing\"\n",
    "with open(data_path+'train_pp.obj', 'rb') as train_pp, \\\n",
    "open(data_path+'test_pp.obj', 'rb') as test_pp:\n",
    "    df_train = pickle.load(train_pp)\n",
    "    df_test = pickle.load(test_pp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental features\n",
    "df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch'] + 1\n",
    "df_test['FamilySize'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
    "\n",
    "df_train = df_train.drop(['SibSp', 'Parch', 'Fare'], axis=1)\n",
    "df_test = df_test.drop(['SibSp', 'Parch', 'Fare'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "dv_train_X = df_train.drop(['PassengerId','Survived'], axis=1).values\n",
    "dv_train_y = df_train['Survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dv_train_X, dv_train_y, test_size=0.25, random_state=1, stratify=dv_train_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "svc_params = {\n",
    "    'kernel': 'linear', # kernel type\n",
    "    'C': 100.0 #regularization parameter\n",
    "}\n",
    "\n",
    "svc = svm.SVC(**svc_params).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANK      FEATURE        SCORE\n",
      "1         Sex             0.73\n",
      "2         Title           0.73\n",
      "3         Pclass          0.38\n",
      "4         FamilySize      0.34\n",
      "5         Embarked_S      0.23\n",
      "6         Embarked_Q      0.14\n",
      "7         Age             0.01\n"
     ]
    }
   ],
   "source": [
    "# Features importance\n",
    "f_name = df_train.drop(['PassengerId','Survived'], axis=1).columns.values\n",
    "f_score = map(lambda x: -x.round(2), svc.coef_[0])\n",
    "\n",
    "print('{:<10}{:10}{:>10}'.format('RANK', 'FEATURE', 'SCORE'))\n",
    "for i, f in enumerate(sorted(zip(f_name, f_score), key=lambda x: x[1], reverse=True)):\n",
    "    print('{:<10}{:10}{:10}'.format(i+1, f[0], f[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of support vectors: 279\n"
     ]
    }
   ],
   "source": [
    "# Number of support vectors\n",
    "print('number of support vectors: {}'.format(len(svc.support_vectors_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with test set: 0.86 (+/- 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Test set score\n",
    "testset_score = svc.score(X_test, y_test)\n",
    "print('Accuracy with test set: {} (+/- {})'\n",
    "      .format(round(testset_score.mean(),2), round(testset_score.std() * 2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with cross-validation (split size = 5): 0.83 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation score\n",
    "cv_iterations = 5\n",
    "cv_score = cross_val_score(svc, dv_train_X, dv_train_y, cv=cv_iterations)\n",
    "print('Accuracy with cross-validation (split size = {}): {} (+/- {})'\n",
    "      .format(cv_iterations, round(cv_score.mean(),2), round(cv_score.std() * 2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on test set\n",
    "dv_test_X = df_test.drop(['PassengerId'], axis=1).values\n",
    "\n",
    "test_prediction_results = pd.DataFrame(\n",
    "    data={'PassengerId': df_test['PassengerId'].values,\n",
    "          'Survived': svc.predict(dv_test_X).astype(int)})\n",
    "\n",
    "# Write results to a csv file\n",
    "test_prediction_results.to_csv(data_path+'outputs/support-vector-machine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
